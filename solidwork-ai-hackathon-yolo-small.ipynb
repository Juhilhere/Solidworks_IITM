{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":125745,"databundleVersionId":14958361,"sourceType":"competition"}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:44:05.645405Z","iopub.execute_input":"2025-12-18T18:44:05.645702Z","iopub.status.idle":"2025-12-18T18:44:09.003861Z","shell.execute_reply.started":"2025-12-18T18:44:05.645675Z","shell.execute_reply":"2025-12-18T18:44:09.003131Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:46:43.831015Z","iopub.execute_input":"2025-12-18T20:46:43.831395Z","iopub.status.idle":"2025-12-18T20:46:44.113137Z","shell.execute_reply.started":"2025-12-18T20:46:43.831363Z","shell.execute_reply":"2025-12-18T20:46:44.112210Z"}},"outputs":[{"name":"stdout","text":"Thu Dec 18 20:46:43 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   76C    P0             42W /   70W |     667MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   43C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport shutil\nimport cv2\nfrom tqdm.auto import tqdm\nfrom ultralytics import YOLO\nfrom sklearn.model_selection import train_test_split\nimport yaml\n\n# Configuration\nINPUT_DIR = '/kaggle/input/solidworks-ai-hackathon'\nWORK_DIR = '/kaggle/working'\nDATASET_DIR = os.path.join(WORK_DIR, 'yolo_dataset')\nIMG_SIZE = 640  # Standard YOLO image size\nBATCH_SIZE = 16\nEPOCHS = 20      # Increase to 50+ for better results\n\n# Class mapping (Order matters for the submission file!)\n# The submission requires: bolt, locatingpin, nut, washer\nCLASSES = ['bolt', 'locatingpin', 'nut', 'washer']\nCLASS_MAP = {name: idx for idx, name in enumerate(CLASSES)}\n\nprint(\"Classes mapped as:\", CLASS_MAP)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:44:09.005184Z","iopub.execute_input":"2025-12-18T18:44:09.005452Z","iopub.status.idle":"2025-12-18T18:44:12.786749Z","shell.execute_reply.started":"2025-12-18T18:44:09.005421Z","shell.execute_reply":"2025-12-18T18:44:12.786020Z"}},"outputs":[{"name":"stdout","text":"Classes mapped as: {'bolt': 0, 'locatingpin': 1, 'nut': 2, 'washer': 3}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Data Preporcessing CSV to YOLO","metadata":{}},{"cell_type":"code","source":"# 1. Prepare Directories\nfor split in ['train', 'val']:\n    os.makedirs(os.path.join(DATASET_DIR, 'images', split), exist_ok=True)\n    os.makedirs(os.path.join(DATASET_DIR, 'labels', split), exist_ok=True)\n\n# 2. Load Metadata\nbboxes_df = pd.read_csv(os.path.join(INPUT_DIR, 'train_bboxes.csv'))\nlabels_df = pd.read_csv(os.path.join(INPUT_DIR, 'train_labels.csv'))\n\n# Get list of all unique training images\nall_images = labels_df['image_name'].unique()\n\n# Split into Train and Validation\ntrain_imgs, val_imgs = train_test_split(all_images, test_size=0.2, random_state=42)\n\ndef process_dataset(image_list, split_name):\n    print(f\"Processing {split_name} data...\")\n    \n    for img_name in tqdm(image_list):\n        # Source path\n        src_img_path = os.path.join(INPUT_DIR, 'train/train', img_name)\n        \n        # Check if image exists\n        if not os.path.exists(src_img_path):\n            continue\n            \n        # Read Image to get dimensions (Synthetic images are likely uniform, but safer to check)\n        img = cv2.imread(src_img_path)\n        h, w, _ = img.shape\n        \n        # Copy image to working directory\n        dst_img_path = os.path.join(DATASET_DIR, 'images', split_name, img_name)\n        shutil.copy(src_img_path, dst_img_path)\n        \n        # Get bboxes for this image\n        img_bboxes = bboxes_df[bboxes_df['image_name'] == img_name]\n        \n        # Prepare Label File content\n        label_path = os.path.join(DATASET_DIR, 'labels', split_name, img_name.replace('.png', '.txt'))\n        \n        with open(label_path, 'w') as f:\n            # If no bboxes, file remains empty (which is correct for background-only images)\n            for _, row in img_bboxes.iterrows():\n                cls_name = row['class']\n                if cls_name not in CLASS_MAP: continue\n                \n                cls_id = CLASS_MAP[cls_name]\n                \n                # Convert xyxy to xywh normalized\n                # x_min, y_min, x_max, y_max provided in CSV\n                x_center = ((row['x_min'] + row['x_max']) / 2) / w\n                y_center = ((row['y_min'] + row['y_max']) / 2) / h\n                width = (row['x_max'] - row['x_min']) / w\n                height = (row['y_max'] - row['y_min']) / h\n                \n                f.write(f\"{cls_id} {x_center} {y_center} {width} {height}\\n\")\n\n# Process both splits\nprocess_dataset(train_imgs, 'train')\nprocess_dataset(val_imgs, 'val')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:44:12.787539Z","iopub.execute_input":"2025-12-18T18:44:12.788211Z","iopub.status.idle":"2025-12-18T18:46:40.201186Z","shell.execute_reply.started":"2025-12-18T18:44:12.788173Z","shell.execute_reply":"2025-12-18T18:46:40.200256Z"}},"outputs":[{"name":"stdout","text":"Processing train data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7805ee242ac547a9901fa6f2fdfb49ba"}},"metadata":{}},{"name":"stdout","text":"Processing val data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c601488cd69d4e859e3c7f5dede92adb"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"yaml_content = f\"\"\"\npath: {DATASET_DIR}\ntrain: images/train\nval: images/val\nnames:\n  0: bolt\n  1: locatingpin\n  2: nut\n  3: washer\n\"\"\"\n\nwith open('data.yaml', 'w') as f:\n    f.write(yaml_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T18:46:40.203270Z","iopub.execute_input":"2025-12-18T18:46:40.203597Z","iopub.status.idle":"2025-12-18T18:46:40.208144Z","shell.execute_reply.started":"2025-12-18T18:46:40.203568Z","shell.execute_reply":"2025-12-18T18:46:40.207455Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load a pretrained model\nmodel = YOLO('yolov8s.pt') \n\n# Train\nresults = model.train(\n    data='data.yaml',\n    epochs=EPOCHS,\n    imgsz=IMG_SIZE,\n    batch=BATCH_SIZE,\n    name='solidworks_parts',\n    device=[0,1],\n    verbose=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T19:48:43.752499Z","iopub.execute_input":"2025-12-18T19:48:43.753038Z","iopub.status.idle":"2025-12-18T20:44:28.055098Z","shell.execute_reply.started":"2025-12-18T19:48:43.753006Z","shell.execute_reply":"2025-12-18T20:44:28.054397Z"}},"outputs":[{"name":"stdout","text":"\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 49.7MB 151.2MB/s 0.3s0.3s<0.0s\nUltralytics 8.3.240 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=0,1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=solidworks_parts3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/solidworks_parts3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding model.yaml nc=80 with nc=4\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \nModel summary: 169 layers, 25,858,636 parameters, 25,858,620 gradients, 79.1 GFLOPs\n\nTransferred 469/475 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 56291 /root/.config/Ultralytics/DDP/_temp_92q13sdm136894102074624.py\nUltralytics 8.3.240 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\nOverriding model.yaml nc=80 with nc=4\nTransferred 469/475 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 975.9Â±350.3 MB/s, size: 27.4 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/train.cache... 8000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8000/8000 134.2Mit/s 0.0s\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 556.9Â±256.6 MB/s, size: 19.3 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/val.cache... 2000 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2000/2000 12.5Mit/s 0.0s\nPlotting labels to /kaggle/working/runs/detect/solidworks_parts3/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/solidworks_parts3\u001b[0m\nStarting training for 20 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/20       3.4G      1.069      1.237      1.107         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.3it/s 2:34<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.6s0.3s\n                   all       2000       5037      0.803      0.871      0.872       0.67\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/20      4.04G     0.8885     0.8414      1.055         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:29<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.6s0.2s\n                   all       2000       5037      0.757      0.667      0.693      0.485\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/20      4.11G     0.7976      0.756      1.027         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:28<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.4s0.3s\n                   all       2000       5037      0.926      0.939      0.975      0.804\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/20      4.11G     0.7436     0.6799      1.008         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.4s0.3s\n                   all       2000       5037      0.765      0.783      0.862      0.634\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/20      4.11G      0.674     0.6142     0.9769         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.7s0.3s\n                   all       2000       5037      0.962      0.958      0.983       0.82\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/20      4.11G     0.6315     0.5668     0.9625         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.7s0.3s\n                   all       2000       5037      0.977      0.977      0.991      0.892\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/20      4.11G     0.5996     0.5286     0.9491         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.9it/s 16.3s0.3s\n                   all       2000       5037      0.395      0.396      0.357      0.208\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/20      4.17G      0.572     0.5112     0.9376         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:28<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.6s0.3s\n                   all       2000       5037      0.997      0.995      0.995      0.908\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/20       4.2G     0.5468      0.478     0.9302         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.8s0.3s\n                   all       2000       5037      0.996      0.996      0.995      0.877\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/20       4.2G     0.5175     0.4514     0.9182         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.9it/s 16.2s0.3s\n                   all       2000       5037      0.997      0.996      0.995      0.884\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/20       4.2G     0.3737     0.2339     0.8429         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:28<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.7it/s 16.9s0.3s\n                   all       2000       5037      0.997      0.997      0.995      0.951\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/20       4.2G     0.3372     0.2108     0.8394         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.5s0.3s\n                   all       2000       5037      0.996      0.996      0.994       0.96\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/20       4.2G     0.3084     0.1977     0.8269         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.5s0.3s\n                   all       2000       5037      0.993      0.991      0.994      0.967\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/20       4.2G     0.2851     0.1808     0.8174         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.6s0.3s\n                   all       2000       5037      0.998      0.999      0.995      0.984\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/20       4.2G     0.2603     0.1655     0.8109         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.8s0.3s\n                   all       2000       5037      0.996      0.997      0.995      0.988\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      16/20       4.2G     0.2399      0.156     0.8089         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.9it/s 16.3s0.3s\n                   all       2000       5037      0.999      0.998      0.995      0.983\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      17/20       4.2G      0.215     0.1444     0.8014         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.6s0.3s\n                   all       2000       5037      0.996      0.998      0.995      0.985\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      18/20      4.24G     0.1941     0.1336     0.7975         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.7s0.3s\n                   all       2000       5037      0.999      0.999      0.995      0.989\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      19/20       4.3G     0.1726       0.12     0.7925         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.5s0.3s\n                   all       2000       5037      0.999      0.999      0.995      0.991\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      20/20       4.3G     0.1554     0.1104     0.7886         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 3.4it/s 2:27<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.8it/s 16.6s0.3s\n                   all       2000       5037      0.999      0.999      0.995      0.991\n\n20 epochs completed in 0.917 hours.\nOptimizer stripped from /kaggle/working/runs/detect/solidworks_parts3/weights/last.pt, 52.0MB\nOptimizer stripped from /kaggle/working/runs/detect/solidworks_parts3/weights/best.pt, 52.0MB\n\nValidating /kaggle/working/runs/detect/solidworks_parts3/weights/best.pt...\nModel summary (fused): 92 layers, 25,842,076 parameters, 0 gradients, 78.7 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 63/63 3.5it/s 17.8s0.2s\n                   all       2000       5037      0.999      0.999      0.995      0.991\n                  bolt       1001       1283          1          1      0.995      0.993\n           locatingpin        965       1219      0.999      0.998      0.995       0.99\n                   nut        981       1285          1          1      0.995      0.989\n                washer        971       1250      0.997          1      0.995      0.992\nSpeed: 0.1ms preprocess, 5.2ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/solidworks_parts3\u001b[0m\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Directory containing test images\nTEST_IMG_DIR = os.path.join(INPUT_DIR, 'test/test')\ntest_images = [f for f in os.listdir(TEST_IMG_DIR) if f.endswith('.png')]\n\nsubmission_rows = []\nprint(\"Running inference on test set...\")\n\n# Run inference in batches (or one by one)\n# stream=True helps with memory on large datasets\nresults = model.predict(source=TEST_IMG_DIR, stream=True, conf=0.25, verbose=False)\n\nfor result in results:\n    img_name = os.path.basename(result.path)\n    \n    # Initialize counts\n    counts = {\n        'bolt': 0,\n        'locatingpin': 0,\n        'nut': 0,\n        'washer': 0\n    }\n    \n    # result.boxes.cls contains the class IDs of detections\n    # Move to CPU and convert to numpy for counting\n    det_classes = result.boxes.cls.cpu().numpy().astype(int)\n    \n    for cls_id in det_classes:\n        # Map ID back to name using the CLASSES list\n        # 0->bolt, 1->locatingpin, 2->nut, 3->washer\n        if cls_id < len(CLASSES):\n            class_name = CLASSES[cls_id]\n            counts[class_name] += 1\n            \n    # Prepare row\n    row = {\n        'image_name': img_name,\n        'bolt': counts['bolt'],\n        'locatingpin': counts['locatingpin'],\n        'nut': counts['nut'],\n        'washer': counts['washer']\n    }\n    submission_rows.append(row)\n\n# Create DataFrame\nsubmission_df = pd.DataFrame(submission_rows)\n\n# Reorder columns to match requirement exactly\nsubmission_df = submission_df[['image_name', 'bolt', 'locatingpin', 'nut', 'washer']]\n\n# Save submission\nsubmission_df.to_csv('/kaggle/working/submission2.csv', index=False)\nprint(\"Submission.csv created successfully!\")\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T20:45:36.161389Z","iopub.execute_input":"2025-12-18T20:45:36.161687Z","iopub.status.idle":"2025-12-18T20:46:43.540524Z","shell.execute_reply.started":"2025-12-18T20:45:36.161657Z","shell.execute_reply":"2025-12-18T20:46:43.539893Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Running inference on test set...\nSubmission.csv created successfully!\n                             image_name  bolt  locatingpin  nut  washer\n0  0040313aa7c7478c8ca264bf573c53fe.png     1            3    0       0\n1  0080e45f4375443b96ee81dc04075117.png     2            0    0       1\n2  0086da1a1914469caa4d042f8e4e94ef.png     0            0    0       1\n3  009ccd5b64a043e0afbae0f840f7cfd4.png     0            0    0       1\n4  00a522a027b24fcfb8ee0857655b953d.png     0            1    0       0\n","output_type":"stream"}],"execution_count":15}]}